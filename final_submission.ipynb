{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "from datetime import datetime\n",
    "from matplotlib.pylab import rcParams\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve \n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_score\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "import warnings\n",
    "import itertools\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from darts.metrics import mape\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "rcParams['figure.figsize'] = 15, 5\n",
    "\n",
    "train_mode = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = ['MELT_TEMP', 'MOTORSPEED']\n",
    "\n",
    "df_ = pd.read_csv('./public/data/raw_data.csv')\n",
    "\n",
    "df_['TAG'] = df_['TAG'] == 'NG'\n",
    "\n",
    "df_.index = pd.date_range(start='3/4/2020', end='5/1/2020', freq='6S')[:-1]\n",
    "\n",
    "df_.drop(columns=['STD_DT', 'NUM', 'MELT_WEIGHT', 'INSP'], inplace=True)\n",
    "\n",
    "df_ = df_.astype(np.float32)\n",
    "df_['TAG'] = df_['TAG'].astype(bool)\n",
    "\n",
    "df_.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_.copy(False)\n",
    "\n",
    "val_start_day = 25\n",
    "\n",
    "train_index = (df.index.month == 3) & (df.index.day < val_start_day)\n",
    "val_index = (df.index.month == 3) & (df.index.day >= val_start_day)\n",
    "\n",
    "train_df = df[train_index]\n",
    "val_df = df[val_index]\n",
    "total_df = df\n",
    "\n",
    "x_train = train_df\n",
    "y_train = pd.DataFrame(x_train.pop('TAG'), columns=['TAG'])\n",
    "\n",
    "x_val = val_df\n",
    "y_val = pd.DataFrame(x_val.pop('TAG'), columns=['TAG'])\n",
    "\n",
    "x_total = total_df\n",
    "y_total = pd.DataFrame(x_total.pop('TAG'), columns=['TAG'])\n",
    "\n",
    "x_train = TimeSeries.from_dataframe(x_train, freq='6S', fill_missing_dates=True)\n",
    "y_train = TimeSeries.from_dataframe(y_train, freq='6S', fill_missing_dates=True)\n",
    "x_val = TimeSeries.from_dataframe(x_val, freq='6S', fill_missing_dates=True)\n",
    "y_val = TimeSeries.from_dataframe(y_val, freq='6S', fill_missing_dates=True)\n",
    "x_total = TimeSeries.from_dataframe(x_total, freq='6S', fill_missing_dates=True)\n",
    "y_total = TimeSeries.from_dataframe(y_total, freq='6S', fill_missing_dates=True)\n",
    "\n",
    "len(x_train), len(x_val), len(x_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler(scaler=MinMaxScaler())\n",
    "\n",
    "x_train = scaler.fit_transform(x_train).astype(np.float32)\n",
    "x_val = scaler.transform(x_val).astype(np.float32)\n",
    "x_total = scaler.transform(x_total).astype(np.float32)\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 시계열 예측 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import TransformerModel\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "forecast_window_size = 30\n",
    "\n",
    "my_stopper = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    min_delta=0.001,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "model_name = 'transformer'\n",
    "epoch = 10\n",
    "\n",
    "forecast_model = TransformerModel(\n",
    "    input_chunk_length=forecast_window_size,\n",
    "    output_chunk_length=1,\n",
    "    batch_size=512,\n",
    "    dropout=0.15,\n",
    "    d_model=16,\n",
    "    nhead=4,\n",
    "    num_encoder_layers=2,\n",
    "    num_decoder_layers=2,\n",
    "    dim_feedforward=16,\n",
    "    model_name=model_name,\n",
    "    activation=\"relu\",\n",
    "    random_state=42,\n",
    "    pl_trainer_kwargs={\n",
    "        \"accelerator\": \"gpu\",\n",
    "        \"devices\": [0]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_mode:\n",
    "    forecast_model.fit(\n",
    "        series=x_train,\n",
    "        val_series=x_val,\n",
    "        verbose=True,\n",
    "        epochs=epoch\n",
    "    )\n",
    "else:\n",
    "    forecast_model = forecast_model.load(\n",
    "        f'./public/models/forecasting/{forecast_model.model_name}.pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3. 4월 첫째 주 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_size = 10\n",
    "hour_size = min_size * 60\n",
    "day_size = hour_size * 24\n",
    "week_size = day_size * 7\n",
    "\n",
    "pred = forecast_model.predict(\n",
    "    n=week_size,\n",
    "    series=x_total[:len(x_train) + len(x_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasted_df = pred.pd_dataframe()\n",
    "\n",
    "ground_truth = y_total[pred.time_index].values().reshape(-1, 1).astype(int)\n",
    "\n",
    "forecasted_df['GT'] = ground_truth\n",
    "\n",
    "forecasted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LightGBM + CatBoost 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. SMOTE를 활용한 데이터 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=0)\n",
    "\n",
    "x_train_over, y_train_over = smote.fit_resample(\n",
    "    X=x_train.values(),\n",
    "    y=y_train.values()\n",
    ")\n",
    "\n",
    "len(x_train), len(x_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_over_df = pd.DataFrame(\n",
    "    x_train_over,\n",
    "    columns=use_cols\n",
    ")\n",
    "\n",
    "y_train_over_df = pd.DataFrame(\n",
    "    y_train_over,\n",
    "    columns=['TAG']\n",
    ")\n",
    "\n",
    "x_val_df = x_val.pd_dataframe()\n",
    "y_val_df = y_val.pd_dataframe()\n",
    "\n",
    "x_train_over_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. LGBM + CatBoost 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = {\n",
    "    \"learning_rate\": [0.06680445610939323],\n",
    "    \"boosting_type\": ['gbdt'],\n",
    "    \"reg_alpha\": [1.0255966382926611],\n",
    "    \"reg_lambda\": [0.17103605819788695],\n",
    "    \"random_state\": [0],\n",
    "}\n",
    "\n",
    "lgbm_clf = LGBMClassifier(random_state=0)\n",
    "lgbm_rcv_ = RandomizedSearchCV(\n",
    "    lgbm_clf,\n",
    "    param_distributions=pars,\n",
    "    n_iter=15,\n",
    "    cv=5,\n",
    "    refit=True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "lgbm_rcv_.fit(x_train_over_df, y_train_over_df)\n",
    "lgbm = lgbm_rcv_.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = {\n",
    "    'iterations': 100,\n",
    "    'random_seed': 0,\n",
    "    'learning_rate': 0.01,\n",
    "    'loss_function': 'Logloss',\n",
    "    'custom_metric': ['Logloss', 'AUC'],\n",
    "    'early_stopping_rounds': 20,\n",
    "    'bagging_temperature': 1,\n",
    "    'verbose': False,\n",
    "}\n",
    "\n",
    "cat = CatBoostClassifier(**pars)\n",
    "cat.fit(Pool(x_train_over_df, y_train_over_df))\n",
    "\n",
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3. 예측된 4월 1일 ~ 4월 7일 데이터에 대한 이상탐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecated_input_df = forecasted_df.loc[:, ['MELT_TEMP', 'MOTORSPEED']]\n",
    "\n",
    "lgbm_pred = lgbm.predict(forecated_input_df).astype(int)\n",
    "cat_pred = cat.predict(forecated_input_df)\n",
    "\n",
    "forecasted_df['LGBM_PRED'] = lgbm_pred.astype(int)\n",
    "forecasted_df['CAT_PRED'] = cat_pred.astype(int)\n",
    "\n",
    "forecasted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. BI-LSTM 기반 이상탐지 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. BI-LSTM 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_size = 8\n",
    "\n",
    "detection_window_size = 10\n",
    "\n",
    "def make_dataset(data, label, window_size=10):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        feature_list.append(np.array(data.iloc[i:i+window_size, :]))\n",
    "        label_list.append(np.array(label.iloc[i+window_size]))\n",
    "    return np.array(feature_list), np.array(label_list)\n",
    "\n",
    "class MockUpModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.ModuleDict({\n",
    "            'lstm': nn.LSTM(\n",
    "                input_size=2,\n",
    "                hidden_size=h_size,\n",
    "                dropout=0.15,\n",
    "                num_layers=1,\n",
    "                batch_first=True,\n",
    "                bidirectional=True\n",
    "            ),\n",
    "            'linear1': nn.Linear(in_features=h_size*2, out_features=1),\n",
    "            'linear2': nn.Linear(in_features=detection_window_size, out_features=1),\n",
    "            'sigmoid': nn.Sigmoid()\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.model['lstm'](x)\n",
    "        out = self.model['linear1'](out)\n",
    "        out = out[:, :, -1]\n",
    "        out = self.model['linear2'](out)\n",
    "        out = self.model['sigmoid'](out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. 입력 윈도우 및 데이터 로더 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_window, y_train_window = make_dataset(x_train_over_df, y_train_over_df)\n",
    "\n",
    "x_val_window, y_val_window = make_dataset(x_val_df, y_val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bs = 256\n",
    "val_bs = 1024\n",
    "\n",
    "x_train_dataloader = DataLoader(\n",
    "    dataset=torch.FloatTensor(x_train_window),\n",
    "    batch_size=train_bs,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "y_train_dataloader = DataLoader(\n",
    "    dataset=torch.FloatTensor(y_train_window),\n",
    "    batch_size=train_bs,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "x_val_dataloader = DataLoader(\n",
    "    dataset=torch.FloatTensor(x_val_window),\n",
    "    batch_size=val_bs,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "y_val_dataloader = DataLoader(\n",
    "    dataset=torch.FloatTensor(y_val_window),\n",
    "    batch_size=val_bs,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-3. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "min_valid = 1e9\n",
    "best_model = MockUpModel().to(device)\n",
    "lstm_model = MockUpModel().to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=lr)\n",
    "\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    batch_loss = 0.\n",
    "    lstm_model.train()\n",
    "    for x, y in tqdm(zip(x_train_dataloader, y_train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        out = lstm_model(x.to(device))\n",
    "        loss = loss_fn(out, y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss += loss.cpu().item()\n",
    "    lstm_model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_fn(lstm_model(x.to(device)), y.to(device)).cpu().item() for x, y in zip(x_val_dataloader, y_val_dataloader))\n",
    "    batch_loss /= len(x_train_dataloader)\n",
    "    valid_loss /= len(x_val_dataloader)\n",
    "\n",
    "    if min_valid >= valid_loss:\n",
    "        min_valid = valid_loss\n",
    "        best_model.load_state_dict(lstm_model.state_dict())\n",
    "    print(f'{i}: loss: {batch_loss}, valid: {valid_loss}')\n",
    "lstm_model = best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-4. 예측된 4월 1일 ~ 4월 7일 값에 대한 이상탐지 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seened_index = len(x_train) + len(x_val)\n",
    "\n",
    "past_data_for_window = x_total[seened_index - 10 : seened_index].values()\n",
    "past_y_data_for_window = y_total[seened_index - 10 : seened_index].values()\n",
    "\n",
    "forecasted_data = forecasted_df.loc[:, ['MELT_TEMP', 'MOTORSPEED']].values\n",
    "forecasted_y_data = forecasted_df.loc[:, ['GT']].values\n",
    "\n",
    "input_x_data = np.concatenate([past_data_for_window, forecasted_data])\n",
    "input_y_data = np.concatenate([past_y_data_for_window, forecasted_y_data])\n",
    "\n",
    "input_x_data, input_y_data = make_dataset(\n",
    "    pd.DataFrame(input_x_data),\n",
    "    pd.DataFrame(input_y_data),\n",
    "    detection_window_size\n",
    ")\n",
    "\n",
    "len(input_x_data) == len(input_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataloader = DataLoader(\n",
    "    dataset=torch.FloatTensor(input_x_data),\n",
    "    batch_size=2048,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "y_dataloader = DataLoader(\n",
    "    dataset=torch.FloatTensor(input_y_data),\n",
    "    batch_size=2048,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for x, y in tqdm(zip(x_dataloader, y_dataloader)):\n",
    "    with torch.no_grad():\n",
    "        res = lstm_model(x.to(device)).cpu().numpy()\n",
    "        res = (res >= 0.5).astype(int)\n",
    "        result.extend(res)\n",
    "forecasted_df['NN_PRED'] = np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 4월1일 ~ 4월7일 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasted_df['FINAL'] = (((forecasted_df['LGBM_PRED'] + forecasted_df['CAT_PRED'] + forecasted_df['NN_PRED']) / 3) >= 0.5).astype(int)\n",
    "\n",
    "pred_df = forecasted_df.loc[:, ['FINAL']]\n",
    "real_df = forecasted_df.loc[:, ['GT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = precision_score(real_df, pred_df)\n",
    "r = recall_score(real_df, pred_df)\n",
    "f1 = f1_score(real_df, pred_df)\n",
    "acc = accuracy_score(real_df, pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'%0.4f' % p, '%0.4f' % r, '%0.4f' % f1, '%0.4f' % acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 4월8일 ~ 4월14일에 대한 동일한 진행\n",
    "## 실제 시스템에는 MLOps가 필수적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_size = 10\n",
    "hour_size = min_size * 60\n",
    "day_size = hour_size * 24\n",
    "week_size = day_size * 7\n",
    "\n",
    "idx = (total_df.index.month == 3) | ((total_df.index.month == 4) & (total_df.index.day <= 7))\n",
    "seened_index = len(total_df[idx])\n",
    "\n",
    "pred = forecast_model.predict(\n",
    "    n=week_size,\n",
    "    series=x_total[:seened_index],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasted_df = pred.pd_dataframe()\n",
    "\n",
    "ground_truth = y_total[pred.time_index].values().reshape(-1, 1).astype(int)\n",
    "\n",
    "forecasted_df['GT'] = ground_truth\n",
    "\n",
    "forecasted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pred = lgbm.predict(forecasted_df.loc[:, ['MELT_TEMP', 'MOTORSPEED']])\n",
    "cat_pred = cat.predict(forecasted_df.loc[:, ['MELT_TEMP', 'MOTORSPEED']])\n",
    "\n",
    "forecasted_df['LGBM_PRED'] = lgbm_pred.astype(int)\n",
    "forecasted_df['CAT_PRED'] = cat_pred.astype(int)\n",
    "\n",
    "forecasted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seened_index = seened_idx\n",
    "\n",
    "past_data_for_window = x_total[seened_index - 10 : seened_index].values()\n",
    "past_y_data_for_window = y_total[seened_index - 10 : seened_index].values()\n",
    "\n",
    "forecasted_data = forecasted_df.loc[:, ['MELT_TEMP', 'MOTORSPEED']].values\n",
    "forecasted_y_data = forecasted_df.loc[:, ['GT']].values\n",
    "\n",
    "input_x_data = np.concatenate([past_data_for_window, forecasted_data])\n",
    "input_y_data = np.concatenate([past_y_data_for_window, forecasted_y_data])\n",
    "\n",
    "input_x_data, input_y_data = make_dataset(\n",
    "    pd.DataFrame(input_x_data),\n",
    "    pd.DataFrame(input_y_data),\n",
    "    detection_window_size\n",
    ")\n",
    "\n",
    "len(input_x_data) == len(input_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataloader = DataLoader(\n",
    "    dataset=torch.FloatTensor(input_x_data),\n",
    "    batch_size=2048,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "y_dataloader = DataLoader(\n",
    "    dataset=torch.FloatTensor(input_y_data),\n",
    "    batch_size=2048,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for x, y in tqdm(zip(x_dataloader, y_dataloader)):\n",
    "    with torch.no_grad():\n",
    "        res = lstm_model(x.to(device)).cpu().numpy()\n",
    "        res = (res >= 0.5).astype(int)\n",
    "        result.extend(res)\n",
    "forecasted_df['NN_PRED'] = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasted_df['FINAL'] = (((forecasted_df['LGBM_PRED'] + forecasted_df['CAT_PRED'] + forecasted_df['NN_PRED']) / 3) >= 0.5).astype(int)\n",
    "\n",
    "pred_df = forecasted_df.loc[:, ['FINAL']]\n",
    "real_df = forecasted_df.loc[:, ['GT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = precision_score(real_df, pred_df)\n",
    "r = recall_score(real_df, pred_df)\n",
    "f1 = f1_score(real_df, pred_df)\n",
    "acc = accuracy_score(real_df, pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'%0.4f' % p, '%0.4f' % r, '%0.4f' % f1, '%0.4f' % acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.7.1 on Python 3.8 (CUDA 11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
